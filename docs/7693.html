<html>
<head>
<title>How to perform Keras hyperparameter optimization x3 faster on TPU for free</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何免费在TPU上更快地执行Keras超参数优化x3</h1>
<blockquote>原文：<a href="https://medium.com/swlh/how-to-perform-keras-hyperparameter-optimization-x3-faster-on-tpu-for-free-602b97812602?source=collection_archive---------3-----------------------#2018-11-27">https://medium.com/swlh/how-to-perform-keras-hyperparameter-optimization-x3-faster-on-tpu-for-free-602b97812602?source=collection_archive---------3-----------------------#2018-11-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c51c6642702342760c754f1b343037c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LjUXT-zUMeRx01sk.png"/></div></div></figure><p id="baae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你是一个数据驱动的科学家或数据工程师，想要完全控制你的Keras模型，并希望从盲目的参数跳跃和搜索中解脱出来吗？</p><p id="81b1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">超参数优化通常需要使用不同的配置多次训练模型，这意味着需要一台带有多个显卡的快速计算机，通过更快地训练模型来减少滞后时间。读完这篇文章后，与在我的单个GTX1070上运行相同的设置相比，您将能够更快地为超参数优化实验x3配置您的Keras模型，并免费在TPU上产生最先进的设置。</p><p id="e7d3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">根据我在Keras支持下的几个开源超参数优化解决方案的经验，<a class="ae jo" href="https://github.com/autonomio/talos" rel="noopener ugc nofollow" target="_blank"> Talos </a>为重要的超参数优化功能提供了最直观、易学和许可的访问。让我们建立一个实验来搜索最佳的CNN模型参数，以使用Talos预测时尚MNIST数据集。</p><h2 id="befd" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">在我的单个GTX1070 GPU上运行超参数优化的基线笔记本和TPU版本都可以在我的<a class="ae jo" href="https://github.com/Tony607/Keras_auto" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得。</h2><h1 id="4e83" class="kk jq hi bd jr kl km kn jv ko kp kq jz kr ks kt kc ku kv kw kf kx ky kz ki la bi translated">为超参数优化准备一个Keras模型</h1><p id="175b" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">与其他一些神经架构搜索工具不同，如<a class="ae jo" href="https://autokeras.com/" rel="noopener ugc nofollow" target="_blank"> Auto-Keras </a>，在超参数优化过程中没有黑盒，由您来指定参数搜索的选项。</p><p id="60a7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">考虑一个在Keras的候选CNN模特来完成你通常写的时尚MNIST分类任务。</p><figure class="lg lh li lj fd ij"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="92db" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要为最佳超参数的Talos扫描准备模型，只需将您想要包含在扫描中的参数替换为对您的参数字典的引用，如下所示:</p><figure class="lg lh li lj fd ij"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="e928" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当Talos扫描正在运行时，<code class="du lm ln lo lp b">params</code>的值将是在扫描期间动态传递给<code class="du lm ln lo lp b">fashion_mnist_fn</code>函数的字典。实现该函数将返回<code class="du lm ln lo lp b">model.fit()</code>的历史度量输出以及<strong class="is lq">模型</strong>本身，以便Talos scanner可以在训练后评估模型的性能。</p><p id="1a1d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面是定义超参数列表并开始搜索的方法。</p><figure class="lg lh li lj fd ij"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="1ea9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Talos支持几种常见的优化策略，对于最简单的网格搜索，参数组合将被插入到您之前为模型训练定义的<code class="du lm ln lo lp b">fashion_mnist_fn</code>中。</p><h1 id="f7ae" class="kk jq hi bd jr kl km kn jv ko kp kq jz kr ks kt kc ku kv kw kf kx ky kz ki la bi translated">对TPU运行超参数扫描</h1><p id="0708" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">如果您运行之前的扫描，它将仅在您的默认TensorFlow设备上运行，无论是CPU还是GPU。</p><p id="497d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然而，要使用云TPU更快地运行整个过程，在构建模型并将模型转换为TPU模型之后，必须执行一些额外的步骤。</p><figure class="lg lh li lj fd ij"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="2a64" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">意识到差异发生在步骤1、3和4中。1024的批量大小将被平均分割成8个TPU核心，每个核心在128个输入样本批量上进行训练。</p><p id="cf40" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">扫描完成后，您可以恢复具有最高验证准确性或您选择的其他指标的最佳模型索引。</p><figure class="lg lh li lj fd ij"><div class="bz dy l di"><div class="lk ll l"/></div></figure><h1 id="5e34" class="kk jq hi bd jr kl km kn jv ko kp kq jz kr ks kt kc ku kv kw kf kx ky kz ki la bi translated">基准和结论</h1><p id="eea5" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">与在我的GTX 1070上的<strong class="is lq"> 40:18 </strong>训练相比，在TPU上用可变超参数完全训练CNN的8个变体需要<strong class="is lq"> 12:29 </strong>。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/bbdd6cdc279a87464ba9d19511cffa4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eHr39LyJU3VoFqKJ.png"/></div></div><figcaption class="lr ls et er es lt lu bd b be z dx">TPU searching</figcaption></figure><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/c10ed1057d07aa02e7612d1e22154e64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5iaSQA-x8nzW1lOk.png"/></div></div><figcaption class="lr ls et er es lt lu bd b be z dx">GPU searching</figcaption></figure><p id="9d29" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请务必查看本教程的可运行的Colab <a class="ae jo" href="https://colab.research.google.com/drive/1kpCDInclZHLOvb-9MOgQHUfJfsg8748Z#scrollTo=Nisl1TBijJFp" rel="noopener ugc nofollow" target="_blank">笔记本</a>和我的<a class="ae jo" href="https://github.com/Tony607/Keras_auto" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的GPU/CPU对等物Jupyter笔记本。</p><p id="31a9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">想用TPU训练一辆速度快20倍的RNN Keras吗？阅读我以前的帖子— <a class="ae jo" href="https://www.dlology.com/blog/how-to-train-keras-model-x20-times-faster-with-tpu-for-free/" rel="noopener ugc nofollow" target="_blank">如何免费用TPU训练Keras model x20倍。</a></p><p id="ff4c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另外，在Github 上阅读更多关于<a class="ae jo" href="https://github.com/autonomio/talos" rel="noopener ugc nofollow" target="_blank"> Talos的内容。</a></p><p id="6c7b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jo" href="https://twitter.com/intent/tweet?url=https%3A//www.dlology.com/blog/how-to-perform-keras-hyperparameter-optimization-on-tpu-for-free/&amp;text=How%20to%20perform%20Keras%20hyperparameter%20optimization%20x3%20faster%20on%20TPU%20for%20free" rel="noopener ugc nofollow" target="_blank">在Twitter上分享</a> <a class="ae jo" href="https://www.facebook.com/sharer/sharer.php?u=https://www.dlology.com/blog/how-to-perform-keras-hyperparameter-optimization-on-tpu-for-free/" rel="noopener ugc nofollow" target="_blank">在脸书分享</a></p></div><div class="ab cl lw lx gp ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="hb hc hd he hf"><p id="ceec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="md">原载于</em><a class="ae jo" href="https://www.dlology.com/blog/how-to-perform-keras-hyperparameter-optimization-on-tpu-for-free/" rel="noopener ugc nofollow" target="_blank"><em class="md"/></a><em class="md">。</em></p><div class="me mf ez fb mg mh"><a href="https://github.com/Tony607/Keras_auto" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="hj b fi z dy mm ea eb mn ed ef hh bi translated">Tony607/Keras_auto</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">如何在TPU上更快地执行Keras超参数优化x3-免费Tony607/Keras_auto</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">github.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv io mh"/></div></div></a></div><figure class="lg lh li lj fd ij er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es mw"><img src="../Images/308a8d84fb9b2fab43d66c117fcc4bb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YqDjlKFwScoQYQ62DWEdig.png"/></div></a></figure><h2 id="c148" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">这篇文章发表在<a class="ae jo" href="https://medium.com/swlh" rel="noopener"> The Startup </a>上，这是Medium最大的创业刊物，拥有+393，714名读者。</h2><h2 id="869c" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">在这里订阅接收<a class="ae jo" href="http://growthsupply.com/the-startup-newsletter/" rel="noopener ugc nofollow" target="_blank">我们的头条新闻</a>。</h2><figure class="lg lh li lj fd ij er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es mw"><img src="../Images/b0164736ea17a63403e660de5dedf91a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ouK9XR4xuNWtCes-TIUNAw.png"/></div></a></figure></div></div>    
</body>
</html>