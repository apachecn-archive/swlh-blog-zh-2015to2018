<html>
<head>
<title>Only Numpy: Noise Training - Training a Neural Network without Back Propagation with Interactive Code.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">only Numpy:Noise Training——用交互式代码训练一个没有反向传播的神经网络。</h1>
<blockquote>原文：<a href="https://medium.com/swlh/only-numpy-noise-training-training-a-neural-network-without-back-propagation-with-interactive-ad775f04cad6#2018-02-01">https://medium.com/swlh/only-numpy-noise-training-training-a-neural-network-without-back-propagation-with-interactive-ad775f04cad6#2018-02-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a3f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">今天我想做一些非常不同的事情。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="ee7f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">我的绝对无厘头理论</strong></p><p id="9954" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我在想，在朝鲜我们有一个词叫做이열치열.它的意思是以火攻火或以武制武。我的父母会在夏天/冬天天气太热/太冷的时候告诉我这些。他们会告诉我吃或喝热汤/冰淇淋来消除炎热/寒冷。回想一下，逻辑没有任何意义，但是要把这个想法记在心里，同时阅读下一部分。</p><p id="d098" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">神经网络的一个挑战是知道隐藏层中给定数据的基本事实表示。简单地说，我们没有隐藏层的地面真实值，所以自然我们不知道数据是如何在那些隐藏层中被<em class="jl">假定</em>表示的。</p><p id="6522" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是我们需要隐藏层让网络执行复杂的任务。直接引用辛顿博士、鲁梅尔哈特博士和威廉姆斯博士在1986年发表的论文“L <a class="ae jm" href="http://www.cs.toronto.edu/~fritz/absps/pdp8.pdf" rel="noopener ugc nofollow" target="_blank">通过错误传播获得内部表征</a>”。</p><blockquote class="jn jo jp"><p id="1c9e" class="if ig jl ih b ii ij ik il im in io ip jq ir is it jr iv iw ix js iz ja jb jc hb bi translated">这个问题和许多类似的问题不能由没有隐藏单元的网络来解决，这些隐藏单元用来创建它们自己的输入模式的内部表示。</p></blockquote><p id="e2b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">非常好的例子是经典的异或问题。</p><p id="6e6d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这也是我对NN的理解。模型试图学习或识别给定数据中的模式。一旦从训练数据中学习到某种模式。我们可以利用这种模式对图像或病人健康状况等进行分类..<br/>然而，数据可能包含噪声，这使得模型更难学习识别该模式的适当权重。</p><p id="fbc7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从这里，我开始思考，我们能不能用噪音抵消数据中的噪音？</p><p id="459a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">就像余弦波和正弦波是如何相互抵消的，就像이열치열，我们能以噪声对抗噪声吗？我想测试这个想法。</p><p id="c78d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">警告！</strong> <br/>我不擅长数学，这种方法也没有确凿的证据证明为什么<em class="jl">会有点</em>的效果。如果任何数学家确切地知道为什么会发生这种情况(以及这背后的理论)，请在下面评论。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="5be6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">数据/网络架构/前馈操作</strong></p><div class="jt ju jv jw fd ab cb"><figure class="jx jy jz ka kb kc kd paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><img src="../Images/6c1f224dcc5af086a999bd38135cceea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*UHXW-8g2SRQTC4BYbE6VTA.png"/></div></figure><figure class="jx jy kk ka kb kc kd paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><img src="../Images/03793fe49fc9b439f81ef88c2ad3cc77.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*1oRz4wLuz-s_lxLXWumtDA.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx kp di kq kr">Left Image Preparing Data || Right Image Forward Feed Operation</figcaption></figure></div><p id="955f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将用简单的分类问题来测试噪声训练的想法。给定MNIST数据，我们将只对0或1图像执行分类。如右图所示，我们的神经网络是一个简单的三层网络。我们所有的网络共享完全相同的架构以及相同的超级参数。最后，我们使用平均N2成本函数。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="ccd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">适当的反向传播</strong></p><figure class="jt ju jv jw fd jy er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es ks"><img src="../Images/a4dd9ed44d9ddae8d2fdba94be99e481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p_vwGTVrhOgBSLXpJlrABg.png"/></div></div></figure><p id="c612" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如上所述，我们有适当的反向传播，其中保持链规则，我们没有任何破坏任何导数。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="8b8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">噪声训练反向传播</strong></p><figure class="jt ju jv jw fd jy er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es kt"><img src="../Images/730d94de73352be06b86d6c0101a2f56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bF9ZADMM21X041sEZR2Juw.png"/></div></div></figure><p id="bf4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">红框→我们网络的成本函数再次，我们使用平均N2成本。</p><p id="1bf8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">蓝框→这是我们网络的关键区别！我们正在生成随机噪声(在上面的例子中，我们正在生成Gumbel分布。)为什么？因为我们要用这个作为我们的梯度，来更新我们的权重。</p><p id="8bbb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">灰色框→这里我们要更新我们的权重。请注意(w3g，b3g) (w3g，b2g)和(w1g，b1g)的区别。如果我们让“成本”成为网络的一个信号，网络是如何运作的。那么我们可以很容易地假设这一点。随着网络运行良好，信号衰减，因此权重的更新变得更小。</p><p id="46fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">对于(w3g，b3g)我们乘以0.01 →给权值以小信号<br/>对于(w2g，b2g)我们乘以0.1 →给权值以中等信号<br/>对于(w1g，b1g)我们乘以1.0 →给权值以大信号</strong></p><p id="b079" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">绿框→逐步学习率衰减</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="e6bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">使用的随机分布列表</strong></p><figure class="jt ju jv jw fd jy er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es ku"><img src="../Images/633c7bc0da5d84604ed8624d197aaf59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6UbFgmuM7atFjJxvSertTg.png"/></div></div></figure><p id="452f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">包括反向传播，共有14种方法来训练每个网络。</p><p id="0763" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a → <a class="ae jm" href="https://en.wikipedia.org/wiki/Gumbel_distribution" rel="noopener ugc nofollow" target="_blank">冈贝尔分布</a> <br/> b → <a class="ae jm" href="https://en.wikipedia.org/wiki/Normal_distribution" rel="noopener ugc nofollow" target="_blank">高斯分布</a> <br/> c → <a class="ae jm" href="https://en.wikipedia.org/wiki/Normal_distribution#Standard_normal_distribution" rel="noopener ugc nofollow" target="_blank">标准正态分布</a>。<br/> d → <a class="ae jm" href="https://en.wikipedia.org/wiki/Binomial_distribution" rel="noopener ugc nofollow" target="_blank">二项式分布</a> <br/> e → <a class="ae jm" href="https://en.wikipedia.org/wiki/Beta_Distribution" rel="noopener ugc nofollow" target="_blank">贝塔分布</a> <br/> f → <a class="ae jm" href="https://en.wikipedia.org/wiki/Poisson_distribution" rel="noopener ugc nofollow" target="_blank">泊松分布</a> <br/> g → <a class="ae jm" href="https://en.wikipedia.org/wiki/Zipf%27s_law" rel="noopener ugc nofollow" target="_blank"> Zipf分布</a> <br/> h → <a class="ae jm" href="https://en.wikipedia.org/wiki/Pareto_distribution" rel="noopener ugc nofollow" target="_blank">帕累托分布</a> <br/> i → <a class="ae jm" href="http://www.nematrian.com/PowerFunctionDistribution" rel="noopener ugc nofollow" target="_blank">幂分布</a> <br/> j → <a class="ae jm" href="https://en.wikipedia.org/wiki/Rayleigh_distribution" rel="noopener ugc nofollow" target="_blank">瑞利分布</a> <br/> k → <a class="ae jm" href="https://en.wikipedia.org/wiki/Triangular_distribution" rel="noopener ugc nofollow" target="_blank">三角形</a></p><p id="6fe0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个发行版的更详细描述可以在Scipy文档中找到，要查看它们，请<a class="ae jm" href="https://docs.scipy.org/doc/numpy/reference/routines.random.html" rel="noopener ugc nofollow" target="_blank">点击此链接。</a>另外，请注意每个发行版的字母符号，因为我将引用它们来代表网络。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="8569" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">训练结果—第100个历元数</strong></p><figure class="jt ju jv jw fd jy er es paragraph-image"><div class="er es kv"><img src="../Images/03d618ef6667cfd58c4ea4bd2dc3fa48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*-4u5k_KqKDLngh7hGztI_A.png"/></div></figure><p id="28b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如上所述，n(反向传播)花了最多的时间来训练，对于其他网络，它大约是77秒到101秒。这是预料之中的，因为反向传播需要在更新权重之前计算大量导数。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="7e0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">训练结果——20幅测试图像中误分类图像的数量</strong></p><figure class="jt ju jv jw fd jy er es paragraph-image"><div class="er es kv"><img src="../Images/549378db924524db28b79bf3a0bf0920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*iOvMT-3CZf1UofNEFr7ECw.png"/></div></figure><p id="9932" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我知道测试集只包含20幅图像，但是我仍然很高兴看到a ( <a class="ae jm" href="https://en.wikipedia.org/wiki/Gumbel_distribution" rel="noopener ugc nofollow" target="_blank"> Gumbel分布</a>)网络和e (Beta分布)网络表现得相当好。只有两个错误分类的图像。然而，当然他们两个都没有达到反向传播模型n的精度，后者有100%的精度。</p><p id="f892" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我想我们做了一些交易。在反向传播上训练神经网络花费最长的时间，然而具有最高的精度。在有噪声的情况下，训练时间较短，但准确度一般。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="629e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">互动码</strong></p><figure class="jt ju jv jw fd jy er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es kw"><img src="../Images/62e8b5e8c27c9fe2f7f0fcc4ec036a82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fAfOxUig_nng89nxWJGIhw.png"/></div></div></figure><p id="1ce6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk"> <em class="jl">警告！如红框所示，整个程序的总运行时间约为1349秒。所以当你运行它的时候拿一杯咖啡。该计划将生成图像后，运行所有的网络，你可以访问他们所有的标签上显示的绿色方框。</em> </strong></p><p id="902a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要访问<a class="ae jm" href="https://repl.it/@Jae_DukDuk/Noise-Training" rel="noopener ugc nofollow" target="_blank">互动代码，请点击此链接。</a></p><p id="5cb1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk"> <em class="jl">警告2。所以我刚刚注意到，如果你不是Repl(交互式代码网站)的订户，你就不能完全运行代码。运行这段代码的另一种方法是从网上下载所有文件，并在本地设置上运行。</em>T13】</strong></p><p id="0c7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jl">更新:为了交互代码，我搬到了Google Colab！所以你需要一个谷歌帐户来查看代码，你也不能在谷歌实验室运行只读脚本，所以在你的操场上做一个副本。编码快乐！然而，在移动后，我注意到一些非常不同的东西，因为Tensorflow的MNIST数据集是以不同的顺序排列的，当训练时，结果会与上面的一些不同。改变Numpy的随机种子值有助于改善或恶化我的结果。最后，我永远不会请求允许访问你在Google Drive上的文件，仅供参考。</em></p><p id="10c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要访问<a class="ae jm" href="https://colab.research.google.com/notebook#fileId=17iKOvcZ90UV89yF6JQtqa2rbUEhq0ucK" rel="noopener ugc nofollow" target="_blank"> Google Colab版本的交互代码，请点击此处。</a></p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="6c2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">遗言</strong></p><p id="9e2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我想指出两件事。首先，我认为反向传播是深度神经网络的最佳训练方法之一，并坚信它在未来仍将是最好的方法之一。</p><p id="3120" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二，整个实验是为了看看是否有可能在没有反向传播的情况下“稍微”训练一个神经网络，我认为我们在一定程度上做到了。然而，有一个巨大的问题。如果我们绘制每个网络的成本值，我们会得到如下图。</p><figure class="jt ju jv jw fd jy er es paragraph-image"><div class="er es kv"><img src="../Images/d0271d84f3f901a1e5b49b5ffb5913c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*c77RUYNbo8ewa3SqiwrMtQ.png"/></div></figure><p id="6a0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如上所示，一个(<a class="ae jm" href="https://en.wikipedia.org/wiki/Gumbel_distribution" rel="noopener ugc nofollow" target="_blank">冈贝尔分布</a>)网络在成本值为0.2(红框)左右停止学习。而n(反向传播)网络能够将代价降低到0。(绿框)所以我不认为香草梯度体面是一个合适的噪声训练优化算法。知道如何有效地摆脱局部最小点以及所有这些背后的精确数学将是非常令人满意的。</p><p id="d554" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果发现任何错误，请发电子邮件到jae.duk.seo@gmail.com找我。</p><p id="ccc9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同时，在我的推特<a class="ae jm" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，访问<a class="ae jm" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae jm" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>了解更多内容。如果你感兴趣，我还在这里做了解耦神经网络<a class="ae jm" href="https://becominghuman.ai/only-numpy-implementing-and-comparing-combination-of-google-brains-decoupled-neural-interfaces-6712e758c1af" rel="noopener ugc nofollow" target="_blank">的比较。</a></p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="5de0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih jk">参考</strong></p><ol class=""><li id="3b33" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated">随机抽样(numpy.random)。(未注明)。检索于2018年2月1日，来自<a class="ae jm" href="https://docs.scipy.org/doc/numpy/reference/routines.random.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy/reference/routines . random . html</a></li><li id="a33b" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">鲁梅尔哈特，丁顿，通用电气公司和威廉姆斯，R. J. (1985)。<em class="jl">通过错误传播学习内部表示</em>(编号ICS-8506)。加州大学圣地亚哥拉荷亚认知科学研究所。</li><li id="3f8b" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">T.(2009年9月17日)。了解你的分销类型。检索于2018年2月1日，来自<a class="ae jm" href="https://www.youtube.com/watch?v=-PwugYB9Zjs" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=-PwugYB9Zjs</a></li><li id="84e3" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">动词 （verb的缩写）(2011年01月07日)。数学教程:描述统计分布(第1部分，共2部分)。检索于2018年2月1日，来自<a class="ae jm" href="https://www.youtube.com/watch?v=achLJ8PRyBw" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=achLJ8PRyBw</a></li><li id="a7d7" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">C.(2014年6月30日)。理解随机变量-概率分布1。检索于2018年2月1日，来自<a class="ae jm" href="https://www.youtube.com/watch?v=lHCpYeFvTs0" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=lHCpYeFvTs0</a></li></ol><figure class="jt ju jv jw fd jy er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es ll"><img src="../Images/731acf26f5d44fdc58d99a6388fe935d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6gfnVvkMRFtjVsWF7vkClA.png"/></div></div></figure><h2 id="fd41" class="lm ln hi bd lo lp lq lr ls lt lu lv lw iq lx ly lz iu ma mb mc iy md me mf mg bi translated">这个故事发表在<a class="ae jm" href="https://medium.com/swlh" rel="noopener"> The Startup </a>上，这是Medium最大的企业家出版物，拥有293，189+人。</h2><h2 id="7945" class="lm ln hi bd lo lp lq lr ls lt lu lv lw iq lx ly lz iu ma mb mc iy md me mf mg bi translated">在这里订阅接收<a class="ae jm" href="http://growthsupply.com/the-startup-newsletter/" rel="noopener ugc nofollow" target="_blank">我们的头条新闻</a>。</h2><figure class="jt ju jv jw fd jy er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es ll"><img src="../Images/731acf26f5d44fdc58d99a6388fe935d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6gfnVvkMRFtjVsWF7vkClA.png"/></div></div></figure></div></div>    
</body>
</html>