<html>
<head>
<title>Multi-class classification with focal loss for imbalanced datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡数据集的聚焦损失多类分类</h1>
<blockquote>原文：<a href="https://medium.com/swlh/multi-class-classification-with-focal-loss-for-imbalanced-datasets-c478700e65f5?source=collection_archive---------0-----------------------#2018-12-15">https://medium.com/swlh/multi-class-classification-with-focal-loss-for-imbalanced-datasets-c478700e65f5?source=collection_archive---------0-----------------------#2018-12-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f4c8e0025776ccf6ffcd88f78f157d41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g6gES7bQoDvLrjoB.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx">Focus on hard examples</figcaption></figure><p id="fb22" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">焦损失是今年年初提出的密集物体探测任务。它能够以<strong class="iw js"> 1:1000 </strong>的比例训练前景和背景类别之间不平衡的高度精确的密集物体检测器。本教程将向您展示如何应用焦点损失来训练给定高度不平衡数据集的多类分类器模型。</p><h1 id="5f07" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">背景</h1><p id="662e" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">让我们先来看看不平衡数据集的其他处理方法，以及聚焦损失是如何解决这个问题的。</p><p id="ad7d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在多类分类中，平衡数据集具有均匀分布的目标标注。如果一个类比另一个类有更多的样本，那么它可以被看作是一个不平衡的数据集。这种不平衡导致两个问题:</p><ul class=""><li id="dee9" class="kw kx hi iw b ix iy jb jc jf ky jj kz jn la jr lb lc ld le bi translated">训练是低效的，因为大多数样本是简单的例子，没有贡献有用的学习信号；</li><li id="1453" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lb lc ld le bi translated">简单的例子会淹没训练并导致退化的模型。</li></ul><p id="80c8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">常见的解决方案是执行某种形式的硬负挖掘，在训练或更复杂的采样/重新加权方案中对硬样本进行采样。</p><p id="3ec9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于特定的图像分类，数据扩充技术也是可变的，以便为代表性不足的类别创建合成数据。</p><p id="caee" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">焦点损失旨在通过降低内联体(简单的例子)的权重来解决类别不平衡，这样即使它们的数量很大，它们对总损失的贡献也很小。它侧重于训练一组稀疏的硬例子。</p><h1 id="f174" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">将焦点损失应用于欺诈检测任务</h1><p id="96a4" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">为了进行演示，我们将在Kaggle 上为<a class="ae lk" href="https://www.kaggle.com/ntnu-testimon/paysim1" rel="noopener ugc nofollow" target="_blank">欺诈检测数据集构建一个分类器，该数据集具有极端的类别不平衡，共有6354407个正常案例和8213个欺诈案例，即733:1。对于这种高度不平衡的数据集，该模型可以采取简单的方法，通过猜测所有输入的“正常”来实现733/(733+1) = <strong class="iw js"> 99.86% </strong>的准确性。但是，我们希望该模型能够检测出罕见的欺诈案例。</a></p><p id="506c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了证明焦点损失比通常应用的技术更有效，让我们建立一个用<strong class="iw js"> class_weight </strong>训练的基线模型，它告诉模型“更多地关注”来自代表性不足的欺诈类别的样本。</p><figure class="ll lm ln lo fd ij"><div class="bz dy l di"><div class="lp lq l"/></div><figcaption class="iq ir et er es is it bd b be z dx">Baseline model</figcaption></figure><p id="6154" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">基线模型实现了<strong class="iw js"> 99.87% </strong>的准确率，仅仅比通过猜测所有正常的“简单路线”略好。</p><p id="f5b8" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们还绘制了混淆矩阵来描述给定保留测试集的分类器的性能。您可以看到总共有<strong class="iw js"> 1140+480=1620 </strong>个未分类的案例。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/a519018d05f1676c1234bb6d3004976f.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/0*nkjVcYcLyuGaa6jK.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">Confusing matrix — baseline model</figcaption></figure><p id="e2e0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在让我们将焦点损失应用于同一模型。您可以在下面看到如何将焦点损失定义为Keras的自定义损失函数。</p><figure class="ll lm ln lo fd ij"><div class="bz dy l di"><div class="lp lq l"/></div><figcaption class="iq ir et er es is it bd b be z dx">focal loss model</figcaption></figure><p id="54d2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">焦点损失有两个可调参数。</p><ul class=""><li id="1d2b" class="kw kx hi iw b ix iy jb jc jf ky jj kz jn la jr lb lc ld le bi translated">聚焦参数γ(gamma)平滑地调整简单示例向下加权的速率。当γ = 0时，焦损失相当于分类交叉熵，并且随着γ的增加，调制因子的影响同样增加(γ = 2在实验中效果最好)。</li><li id="f648" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lb lc ld le bi translated">α(alpha):平衡焦点损失，比非α平衡形式的精确度稍有提高。</li></ul><p id="5673" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，让我们将性能与之前的分类器进行比较。</p><p id="7873" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">焦点损失模型:</p><ul class=""><li id="22bd" class="kw kx hi iw b ix iy jb jc jf ky jj kz jn la jr lb lc ld le bi translated">准确率:99.94%</li><li id="7f43" class="kw kx hi iw b ix lf jb lg jf lh jj li jn lj jr lb lc ld le bi translated">总误分类测试集样本:<strong class="iw js"> 766+23=789 </strong>，将错误减少一半。</li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/c06e2f843c05da09cb12ec5bdfef623f.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/0*vBqwZCekZvTZ48IV.png"/></div><figcaption class="iq ir et er es is it bd b be z dx">Confusing matrix — focal loss model</figcaption></figure><h1 id="e361" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论和进一步阅读。</h1><p id="c5d7" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">在这个快速教程中，我们介绍了一个新的工具来处理高度不平衡的数据集——焦点损失。一个具体的例子向您展示如何在Keras API中将焦点损失应用到您的分类模型中。</p><p id="d5ef" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">你可以在我的GitHub 上找到这篇文章<a class="ae lk" href="https://github.com/Tony607/Focal_Loss_Keras" rel="noopener ugc nofollow" target="_blank">的完整源代码。</a></p><p id="9cd1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">关于焦损的详细描述，可以看https://arxiv.org/abs/1708.02002<a class="ae lk" href="https://arxiv.org/abs/1708.02002" rel="noopener ugc nofollow" target="_blank">的论文。</a></p><div class="ls lt ez fb lu lv"><a href="https://github.com/Tony607/Focal_Loss_Keras" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab dw"><div class="lx ab ly cl cj lz"><h2 class="hj b fi z dy ma ea eb mb ed ef hh bi translated">Tony607/Focal_Loss_Keras</h2><div class="mc l"><h3 class="bd b fi z dy ma ea eb mb ed ef dx translated">不平衡数据集的焦点损失多类分类- Tony607/Focal_Loss_Keras</h3></div><div class="md l"><p class="bd b fp z dy ma ea eb mb ed ef dx translated">github.com</p></div></div><div class="me l"><div class="mf l mg mh mi me mj io lv"/></div></div></a></div><p id="ba66" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><a class="ae lk" href="https://twitter.com/intent/tweet?url=https%3A//www.dlology.com/blog/multi-class-classification-with-focal-loss-for-imbalanced-datasets/&amp;text=Multi-class%20classification%20with%20focal%20loss%20for%20imbalanced%20datasets" rel="noopener ugc nofollow" target="_blank">在Twitter上分享</a> <a class="ae lk" href="https://www.facebook.com/sharer/sharer.php?u=https://www.dlology.com/blog/multi-class-classification-with-focal-loss-for-imbalanced-datasets/" rel="noopener ugc nofollow" target="_blank">在脸书分享</a></p></div><div class="ab cl mk ml gp mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="hb hc hd he hf"><p id="e993" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><em class="mr">原载于</em><a class="ae lk" href="https://www.dlology.com/blog/multi-class-classification-with-focal-loss-for-imbalanced-datasets/" rel="noopener ugc nofollow" target="_blank"><em class="mr">www.dlology.com</em></a><em class="mr">。</em></p><figure class="ll lm ln lo fd ij er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es ms"><img src="../Images/308a8d84fb9b2fab43d66c117fcc4bb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YqDjlKFwScoQYQ62DWEdig.png"/></div></a></figure><h2 id="c148" class="mt ju hi bd jv mu mv mw jz mx my mz kd jf na nb kh jj nc nd kl jn ne nf kp ng bi translated">这篇文章发表在<a class="ae lk" href="https://medium.com/swlh" rel="noopener"> The Startup </a>上，这是Medium最大的创业刊物，拥有+399，714名读者。</h2><h2 id="869c" class="mt ju hi bd jv mu mv mw jz mx my mz kd jf na nb kh jj nc nd kl jn ne nf kp ng bi translated">在这里订阅接收<a class="ae lk" href="http://growthsupply.com/the-startup-newsletter/" rel="noopener ugc nofollow" target="_blank">我们的头条新闻</a>。</h2><figure class="ll lm ln lo fd ij er es paragraph-image"><a href="https://medium.com/swlh"><div class="er es ms"><img src="../Images/b0164736ea17a63403e660de5dedf91a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ouK9XR4xuNWtCes-TIUNAw.png"/></div></a></figure></div></div>    
</body>
</html>