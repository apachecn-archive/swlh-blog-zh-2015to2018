# 数据奴役和分散解放

> 原文：<https://medium.com/swlh/data-slavery-and-decentralized-emancipation-ec9cc1265608>

## 脸书、谷歌和数据所有权的未来

![](img/2ab48470fed2e14f227be257983b20d1.png)

仅仅在短短的 400 年前，人类才慢慢意识到这样一个事实，即拥有个人所有权是一种巨大的道德罪恶。几千年来，全球各地的文化已经将其他部落、教派或种族的人类——在没有补偿或同意的情况下——减少到他们建造文明的字面上的次人类经济基础。

值得注意的是，这种模式出现在我们天生的部落倾向和最近的经济刺激的交汇处。奴隶是他们邻居无止境的快速增长的副产品，被致力于以最具成本效益的方式扩大其物质统治的文明的利益所蹂躏。因此，奴隶作为次人类的叙述构成了一种便利的事后的经济上的便利剥削的合理化。但最终我们意识到，这种短视剥削的真正代价是人类自身的灵魂。我们向个人主权的道德要求敞开了我们的思想和心灵；每个人都有一个超然的片段，奴役这样一个片段是对我们集体人性的打击。

这个不道德机构的回声回荡在现代化的大厅里。我们的社会不仅因为过去的罪恶历史，还因为它们现在以强迫劳动、性交易和儿童奴役的形式存在而留下了深深的伤痕。然而，当我们[在努力治愈创伤和减少这些暴行的持久影响方面取得进展的时候](https://www.youtube.com/watch?v=q30BAM65q7c)，另一种不太明显但相当有害的侵犯个人主权的行为几乎吞噬了整个世界。对于非自愿侵犯人类尊严的行为，我要介绍一下*数据奴役的概念。*

当我们在人类社会经济互动的数字海洋中绘制日常路线时，我们在身后留下了我们最有价值的商品的痕迹:我们的身份。通常，在我们不知情或不同意的情况下，这些痕迹被捕获、分类，然后带到市场上卖给出价最高的人。数据所有者使用我们身份的这些片段来创建我们本质的低分辨率全息表示，换句话说，就是我们的行为特征。虽然今天它们的分辨率相对较低，但这个领域的主要参与者一直在努力提高我们行为化身的保真度。例如，如果你要下载你自己的数据模型，如谷歌所见，它可以轻易超过 5GB。为了更好地理解这一点，把每一位——存储 1 或 0 的每一个单元——想象成一个单元。这意味着谷歌使用*440 亿个数字“细胞”*来构建你的虚拟形象。相比之下，[人的大脑只有 160 亿个细胞。由于数据捕获、存储和计算能力的指数增长，这种模型的规模越来越接近进化以普通人体的形式缝合在一起的 37.2 万亿个细胞。](https://en.wikipedia.org/wiki/List_of_animals_by_number_of_neurons)

当然，在大多数情况下，存储的数据是行为的，而不是结构的。像谷歌和脸书这样的公司将指针[指向你看过的广告、你买过的东西、你搜索过的概念、你与之交谈过的人——包括你的说话方式，以及你经过的地点](https://www.theguardian.com/commentisfree/2018/mar/28/all-the-data-facebook-google-has-on-you-privacy)。但是考虑到机器学习的进展速度和足够的行为信息，[人们不需要从头开始对身体和思想建模](https://www.quantamagazine.org/machine-learnings-amazing-ability-to-predict-chaos-20180418/)。我们理解和预测人们行为的能力——高度精确——每天都在增强。除了预测，我们越来越多地构建工具，在被推动者不知情或不同意的情况下，定向推动人类行为。

为了什么？我们已经看到这些趋势侵蚀了心理上的亲密环境。正如 Target 在 2012 年展示的那样，我们已经过了这样一个阶段:在一个女人的意识开始怀疑，更不用说期待怀孕的真实性之前，她的数据唤醒可能会泄露她刚刚怀孕的事实。鉴于这种亲密的能力，我不觉得提出矩阵的视觉隐喻是夸张的，在矩阵中，我们身份的碎片全息图被无意识地集中在一起。他们被困在有限的算法空间中，受到拥有行为心理学和数据科学博士学位的数据科学家的戳戳和刺激。第三方企业演员以预测和指导我们对未来刺激、广告或其他事物的真实反应的名义，建立、拥有和控制我们的行为克隆体。为此，拥有我们的数据全息图意味着有能力[向出价最高的人](https://www.facebook.com/business/products/ads)兜售关于我们行为的预测，或者无意中将它们透露给政治行为者，正如最近剑桥分析公司的崩溃所证明的那样。但是，正如扎克伯格在国会陈述的那样——在他自己的烟草大事件中——至少脸书[不会明确出售你的数据](https://www.washingtonpost.com/national/ap-fact-check-facebook-doesnt-sell-data-but-profits-off-it/2018/04/10/f6c3c6e4-3d04-11e8-955b-7d2e19b79966_story.html?noredirect=on&utm_term=.ecf81b37c837)

我们是如何走到这一步，来到这种以数字为媒介的行为奴役形式的？我们是如何如此不知不觉地将我们的主权牺牲给那些乐于将我们的每一个想法货币化而不给予有意义的同意或补偿的人的？如前所述，我认为，我们最近的经济刺激塑造了我们新生的数字经济的道德，就像它们历史上塑造我们的道德一样:*遵循阻力最小的路径*。正如前现代文明在缺乏强大道德规范的情况下利用奴隶劳动作为快速增长的引擎一样相反，我们这个时代的互联网巨头慢慢演变为现代数据奴隶市场的剥削者和交易者。

为了满足他们对短期增长的贪婪胃口，并在缺乏支持数据主权的强大道德规范的情况下，谷歌、苹果和脸书等公司选择了阻力最小的道路，走向了一个相当丑陋的目的地。在线商务慢慢从一个新奇的市场演变为一个行为工厂，在这个市场中，公司获得了以前所未有的便利销售商品和服务的能力，在这个行为工厂中，对有限的消费者注意力供应的贪婪需求推动了一场螺旋上升的数据军备竞赛。正是这种军备竞赛——起初是无意识的——将用户行为商品化，为了短期利益而贬低个人隐私和自主权的未来价值:用户的便利，所有者的利润。

此外，那些将捕获的注意力转化为收入的公司完全有动力增加基本的注意力供给。换句话说，将更多的用户置于多巴胺驱动的参与循环中会为广告植入创造更多的机会。由于缺乏具体的理由来缓和他们对行为剥削的本能，公司忽视了日益垄断用户注意力所带来的负面外部性。当垄断行为目前没有成本时尤其如此。

从历史的角度来看，我们想要维持和促进人类注意力的供给，而这正是网络经济增长的原因，这种欲望非常明显地映射到了先前的身体奴役形式。在这两种情况下，我们都很快将不道德的行为合理化，以维护供应。在没有一个可行的道德框架与之相反的情况下，我们的近因激励经常使我们看不到明显的道德缺陷。当然，这是一幅严峻的画面，因此任何技术人员讨论起来都会感到不舒服，因为这意味着我们手上都沾满了鲜血。这甚至适用于用户——尤其是用户。毕竟，如果没有我们自己反复接受摆在我们面前的浮士德式的讨价还价，不断用我们身份的碎片换取网上购物、外包记忆、扩展智能和社会联系的便利，我们就不可能走到这一步。在这一点上，毫无疑问，我们是许多数字克隆体目前被奴役状态的同谋，在他们不知情的情况下被控制，并用来微妙地指导我们的现实世界行为。

但在我们探索这些趋势的宏观含义之前，我想暂时离开主题，解释一下这些低分辨率数据全息图实际上代表了什么，并进一步界定我关于通过适当的道德透镜来观察其本质的立场。众所周知，大型科技公司正忙于为他们的用户行为建模，只受到机器学习研究和计算能力的前沿限制，并且他们不断试图超越这些限制。但很少有人理解的是，这些用户行为模型从基本的统计试探法发展到世界上最先进的机器学习算法有多快。有了我们的行为数据，这样的系统越来越有能力运行个人行为的快速进化模拟。花点时间让这些暗示深入人心。[我们正在使用自己的数据进行模拟，以便实时预测和指导我们的行为](https://searchengineland.com/patent-1-2-google-learns-influence-control-users-272358)。

当然，今天的模型的分辨率仍然相对较低，但它们的发展似乎遵循着与许多其他信息技术相同的指数加速轨迹。这意味着什么？在没有代表个人数据主权的道德干预的情况下，自然的结局是在没有同意或补偿的情况下对人类行为进行越来越高分辨率的模拟。最终，每个人都有数千个——如果不是数百万个——数字克隆体在后台运行，作为数据驱动的实验室老鼠，为那些收集最多数据和创建最准确模拟的人服务。

然而，我们减弱的能动性只是将这些技术引向其逻辑结论的最明显的负面影响。我们不知道这种模型最终会在多大程度上意识到自己的困境，我们目前也没有将这些技术建立在允许我们作为主权人类有意义地监督和指导在我们众多但不可见的数字自我上进行的实验的基础设施上。除了能够请求脸书和谷歌商店的数据，没有任何机制可以让用户发现私人公司*如何使用他们的数据来模拟和改变我们的行为*。从根本上说，我们的法律框架和道德直觉已经跟不上科技行业的指数增长速度。即使在最严格的监管制度下，私人公司拥有而不仅仅是出租个人数据仍然是一种规范。

我们还必须认真对待一个基本的伦理问题:在数十亿的规模上指导人类的行为——使用越来越有能力和不受约束的行为模拟——是否对自由意志本身构成了有意义的打击？在限制个体机构的因素列表中，我们不假思索地添加了一个私人拥有和运营的机器学习基础设施的庞大网络。这个新的基础设施层形成了一个有意义地塑造人类行为的反馈回路，并且目前以一种与用户的主观长期福祉的考虑很大程度上分离的方式运行。

也许更令人担忧的是，这一层的演变仍然与他们所处社会的长期社会和政治健康的激励机制无关。将驱动机器智能的经济激励与人类的长期利益脱钩，是集体行动问题的终极表现，这一事实不会被那些延续其进步的人忽视。谷歌和脸书等大型科技公司的前雇员和高管已经开始意识到这一现实。最值得注意的是，最近对这种游戏的物种规模利害关系的觉醒是以特里斯坦·哈里斯的[人道技术倡议](http://humanetech.com/)和[查马斯·帕里哈皮蒂亚在斯坦福大学商学院的即兴评论](https://www.youtube.com/watch?v=78oMjNCAayQ)的形式出现的，在这些评论中，他将情况总结为:

> “我们创造了正在撕裂社会运作结构的工具”。

此外，随着机器学习领域的发展，这些行为调整的企业实施将变得越来越不透明——甚至对其创造者也是如此。这源于这样一个事实，即今天的机器学习算法[以类似于我们自己大脑](https://www.youtube.com/watch?v=aircAruvnKk)的方式学习和适应。因此，有理由得出这样的结论:如果有足够的规模，我们很快就会努力理解机器学习算法黑盒内部的行为，甚至比我们已经努力理解自己大脑内部的行为还要多。

鉴于利害攸关，我们必须开始转变我们的道德观。我们必须开始审视我们的模拟自我，因为它们正在迅速变成:*我们的法律人的数字化延伸*。

我们解决这一道德雷区的能力对长期人类自由的游戏理论产生了有意义的影响，而我们的数据全息图在公司和政府机构手中的日益集中播下了巨大的道德风险。纳西姆·塔勒布(Nassim Taleb)等风险理论家正确地指出，没有比鼓励广泛的利益集中和风险分散更快的方式将脆弱性引入系统。这样做通过排除负外部性的准确定价来隐藏风险——特别是低概率的未来灾难。例如，随着用户对非个人化的政治争论上瘾，并在平台上花费更多时间，脸书可能会很容易地集中来自政治极化的利润。但促进一个国家政治对话的两极分化也会带来沉重的代价，尽管脸书及其投资者乐于让整个社会来担水。当然，尽管[平台做出了显而易见的贡献](/@matthewpirkowski/facebook-our-contemporary-colosseum-4176b26787e9)，但脸书之前的广告费率从未计入我们目前政治极化的成本。鉴于目前的技术，他们怎么能做到呢？尽管问题依然存在:这种将行为成本推卸给社会政治公地的做法能持续多久？

在数据驱动的经济中，这些同样的道德不对称几乎无处不在，因为我们缺乏权衡分散的长期成本与拥有我们数据的人的短期激励的机制。令人遗憾的是，我们已经变得非常依赖这些公司开发的工具，这给这一挑战雪上加霜。因此，我们没有对我们集体行为的风险进行准确定价，而是继续为了方便而牺牲我们的隐私和权力。随着时间的推移，这种行为模式倾向于将我们的个人信息集中在极少数人手里，不仅威胁到个人隐私，也威胁到个人政治机构。例如，政府行为者现在可以依靠谷歌、脸书和 Twitter 等公司提取任何目标的信息，理由和透明度越来越少。

作为这些加速趋势的结果，我们实际上是在乞求一个独裁风格的黑天鹅。鉴于目前的激励机制，我们正在努力建设基础设施，以便未来的独裁者可以轻松操纵和控制不合作的公众。如果你认为随着时间的推移，私营企业会有意义地抵制这种压力，[你没有注意到](https://gizmodo.com/facebook-says-government-requests-for-user-data-rose-21-1821396547)。对于一家全球性公司来说，与联邦执法机构的合作——即使是在道德上有问题的借口下——只是做生意的成本，还可能增加他们对新进入者的市场地位的防御能力。结论是:一旦我们将可识别的个人持有钥匙的锁背后的数据集中起来，博弈论预测，抵抗国家强制的能力屈服于由日益高涨的恐惧浪潮驱动的政策，而不是由关于社会长期最佳利益的理性讨论驱动的政策，这只是一个时间问题。我们所走的日益集中的道路无疑是一条路:以方便和安全的名义不断减少自由和隐私的棘轮。

除了国内问题，数据主权还会对地缘政治格局产生重大影响。不承认个人层面的数据主权这一基本权利，政治行为者操纵人口并强加其意识形态议程的趋势只会加速。随着世界各国政府越来越多地利用公民数据进行不必要的胁迫，我们原本民主的治理体系将越来越容易受到暴力反动和专制暴政的影响。这是因为稳定的地缘政治制度和有意义的经济协调需要的不仅仅是国家和企业行为者之间自上而下的协调:它们需要对自下而上来自个人同意的完整性和主权的持久尊重。换句话说，地缘政治一体化需要道德治理，而道德治理需要尊重当前的社会共识和被统治者的持续同意。

从历史上看，这种精神体现在个人主权的启蒙理想中。然而，在方便潮流的侵蚀下，这一文化基石从政治意识的基础下滑落。在我们内心深处，我们感觉这是真的。如果我们忽视这种感觉，那我们就是傻瓜。如果不把唐纳德·川普(Donald Trump)和英国退出欧盟(Donald Trump)这样的人与持续的自上而下的全球化进程联系起来，那我们就太傻了。这一进程把发达国家准备最不充分的群体——又踢又叫——拖入了全球公地。再说一次，如果你不相信你的数据的所有权和使用在这方面起着关键作用，[你没有注意到](https://www.theguardian.com/news/2018/mar/17/cambridge-analytica-facebook-influence-us-election)。如果我们要将道德治理带入一个以数字为媒介的 21 世纪，被治理者的同意必须仍然是最重要的，而数据主权在确保治理保持共识方面发挥着关键作用，不会被那些试图在数据奴役的琴弦上暂停异议(像木偶一样)的人滥用。

与这些伦理理想形成鲜明对比的是，中国即将到来的“T2”公民评分(T3)体现了一种公然的独裁数据奴役制度。这种治理模式不仅不祥地笼罩着中国公民，也笼罩着人类本身，它可能是我们当前道德和技术轨迹的副产品。对于那些不熟悉的人来说，公民评分是一项非常奥威尔式的技术，由中国[现已独裁的共产党](https://www.npr.org/sections/thetwo-way/2018/03/11/592694991/china-removes-presidential-term-limits-enabling-xi-jinping-to-rule-indefinitely)设计，通过使用和滥用广泛的监控，以及未经同意的数据存储和分析，集中定义和实施可接受的价值观和行为。在中国的道德矩阵中，中国公民的政治顺从与他们的经济生存能力和活力有着正式而直接的联系。换句话说，不久的某一天，[每一个中国公民都将在一条政治不正确的微博后醒来，失去支付房租、购买食物或在现实世界中自由行动的能力](https://www.cbsnews.com/news/china-social-credit-system-surveillance-cameras/)。这不是幻想，也不是猜测；这些是目前实地的事实。通过数据控制的完全政治奴役。欢迎来到可扩展威权主义的世界。

在离家更近的地方，我们可以更加清晰地观察到这种数据驱动的控制结构在我们自己的互联网巨头的细微行为推动下的轮廓。如果不要求知情同意(这里定义为用户对任何数据共享协议的实际理解),如果不将个人数据的基本法律所有权交给个人，我们就会无意中更接近数据驱动的威权主义的悬崖边缘。数十亿次温柔的轻推把我们逼到了一个角落，在那里我们不仅永久地放弃了权利，还放弃了表达有意义的异议的能力。尽管事实上，我们自己通往这种行为奴役状态的道路可能不那么痛苦——甚至可能令人愉快——但它对人类能动性和自由的萎缩性影响最终可能会在功能上看起来类似于中国的公民分数。

那么，我们能做些什么来避免这种令人沮丧的独裁未来呢？第一步是认识到我们有一个问题。除了认识之外，我们必须明白，这不是那些目前从数据奴役现状中获利的人可能解决的问题。把狐狸托付给牧羊的母鸡，往好里说是幼稚，往坏里说是凶残。然而，当涉及到人类道德指南针的根本演变时，这并不是什么新鲜事。当第一批废奴主义者开始公开讨论奴隶制作为一个主要的道德问题——作为一种伤害人类灵魂的巨大道德邪恶——他们最坚定的抵抗来自于那些最热衷于这一做法的人。考虑到这一点，我们不应该指望通过在当今高度集权的政府或大型科技公司的范围内工作来实现数据解放，如果数据主权成为道德和法律规范，这两者都将失去相当大的权力。相反，反思巴克明斯特·富勒关于范式进化的永恒建议是有益的:

> “你永远无法通过对抗现有的现实来改变事情。要改变什么，就建立一个新的模式，让现有的模式过时。”

我们不应该试图用现存的、基本上已经过时的治理机制来监管脸书和谷歌，而是应该直接诉诸那些受数据奴役做法影响最大的人的利益:利用技术改善生活质量的个人。但是，在整个社会能够更新其对道德领域的理解之前，我们必须讲述这个故事，以打开一个新的感知框架。我们必须叙述目前看不见的选择，使它们变得不仅仅是可见的，而是可取的，从而加快采用新的道德透镜。为了改变世界的道德面貌，这种道德面貌在人们的心中和头脑中是集体拥有的，我们必须首先描绘一幅人类可能产生共鸣的更美好世界的图景——一个超越目前道德越轨领域的世界。或者，正如弗朗西斯·培根曾经说过的:

> 在蜡板上，你不能写新的东西，除非你把旧的擦掉。用头脑它不是这样；在那里，你不能擦掉旧的，直到你写了新的。

去中心化解放和数据主权的框架提供了这一新的图景。它需要建立新的基础设施，在此基础上，个人自由和个人数据的所有权不仅体现在文字上，而且体现在技术本身的数学基础上。这些数学基础超越了公司和国家行为者，因此将自我主权的权利归还给了个人。想象一下，如果你愿意的话，在这样一个世界里，与你的行为相关的任何数据，事实上的*和法律上的*都归你所有。无论数据存储在何处，或由谁获取，数据的使用对有关各方永远是透明的，并取决于他们持续的自愿参与。这有助于将这视为一种围绕一个人在线足迹整体的加密预防措施——一种智能膜，能够按照你的定义，按照你的最佳利益行事。当您的个人数据在网络世界中传播时，会遇到第三方，他们希望将这些数据用于自己的经济、个人或政治目的。在一个数据主权的世界里，你的数据膜允许这种交互的程度将由你控制的设置来管理，不在任何公司或政府实体的范围之内。**

除了控制第三方使用您的个人数据的权力之外，授予数据主权的网络还引入了取消个人数据访问权限的可能性。如果您决定不再信任第三方提供有问题的信息，您可以撤销它。作为一个用户，你有权直接惩罚那些试图虐待你的虚拟自我的坏人。在一个数据主权的世界里，软件用户保留了行为谈判桌上的席位。这个新的席位不仅可以提供影响个人行为数据使用的灵活性，还可以允许直接参与决定其经济价值的谈判；在解放数据和主权身份的世界中，个人获得了对其数据的经济足迹的代理权，并可以使用个人酌处权来管理数据。与面向监管的解决方案不同，这种基于市场的解决方案允许通过价格数据自下而上地包含隐私和政治不稳定等长期风险。简而言之:如果谷歌和脸书想从你的行为数据中获取更多利润，他们可以相应地补偿你，支付更高的价格来获得双方同意租赁你的数据的权利。

在这一点上，敏锐的读者可能会注意到，这样的提议听起来比大多数人以隐私的名义愿意承担的工作要多——特别是在他们的个人和职业责任之上。此外，这样一个体系可能会引入经济学家罗纳德·科斯(Ronald Coase)创造的交易成本(transaction costs)概念(T1)，即在交易层面增加少量摩擦会对整个体系的整体效率和能力产生巨大的负面影响。幸运的是，在这方面存在一个解决方案:智能合约。智能合同是一种编纂两方或多方之间协议的新方式，它依靠编码博弈论而不是成文法来确保各方遵守合同。这种合同的使用目前还处于初级阶段，但假设在十年内，智能合同与机器学习系统一起使用似乎是正常的，这并不完全激进，机器学习系统可以根据法律意图采取行动——如果被允许为你的个人利益采取行动的话。以这种方式，我们可以利用个人主权人工智能的多样化景观来对冲企业人工智能可能的滥用，而不会给用户带来无法忍受的工作水平，也不会增加不必要的交易成本。

此外，这减轻了在便利的庇护下隐藏不对称风险的倾向。通过允许拥有自我主权的个人直接参与市场——他们自己产生经济引擎赖以运转的数据——我们可以重新平衡拥有数据者和数据被拥有者之间的不对称。这让我们的基本人性远离了当前的数据利用模式，让我们的数字经济更接近激励导向的自由市场。

最后，引入用户作为市场参与者，能够代表他们的数据以经济的方式行事，在自动化程度日益提高的世界中，允许更可持续的闭环经济模式。人们可以将这一循环概念化为一种数据驱动的普遍基本收入。这样一个循环在理论上可以平滑自动化驱动的失业浪潮可能带来的需求冲击，因此有助于缓和大规模经济流离失所带来的大规模政治动荡。实施这种形式的 UBI 将代表着向新兴的、基于市场的行为经济迈进了一步，这种行为经济以自上而下、以国家为中心的 UBI 形式所不具备的方式保留了对个人自主性和行为多样性的尊重。这是因为——尽管意图是好的——自上而下的 UBI 的专制本质源于封闭系统内平均分配 UBI 的通胀压力。因此，为了避免因通货膨胀而失去效用，实施大规模的全民医保计划将有利于财富的差别分配。鉴于差别分配需要一个行为准则来指导资金分配——而国家行为者可能会在我们的政治体系内集中决定这一行为准则——缺乏分散解放的普遍不平等开始看起来有点像中国的公民得分。

无论如何，如果数据主权的假设优势听起来好得令人难以置信，它们就不是真的。这些不是对遥远未来的描述；今天，第一步已经触手可及。

但是为了达到这个目标，我们必须愿意改变我们的行为。我们必须确定，数据奴役和技术授权的独裁主义事实上构成了对个人主权和人类自由的威胁，因此是极其重要的道德问题。沿着这些思路，你可能已经听说过比特币。但是比特币仅仅代表了无限创意和快速扩张的加密社区的技术冰山一角。许多有隐私意识的个人组成了这个意识形态折衷的群体，他们中的大多数人希望将一个数据主权的世界带入现实。例如， [Blockstack](https://blockstack.org/) 就是这样一家公司，致力于建设一个“[新互联网](https://www.newyorker.com/tech/elements/the-mission-to-decentralize-the-internet)”，其协议从根本上来说是去中心化的，并且将允许上面提到的大多数概念。但是他们并不孤单。全球各地成千上万的企业家正在努力工作，创造加密工具来管理整个 21 世纪社会的道德信息流。同样，寒武纪大爆发的幸存者塑造了生命自身的发展道路，那些在隐秘的寒武纪中幸存下来的人将对人类未来的经济发展道路产生巨大的影响。

我们正站在一个转折点上。在一个以信息为基础的世界中，我们必须超越管理数据所有权模式的道德架构的发展:我们必须体现与分散解放相关的道德直觉。如果我们今天走错了路，就不能保证我们会重新获得控制数据的机会。此外，数据越来越多地驱动我们的数字生活这一事实也带来了一条禁令:*我们* *不仅要控制我们的数字自我*，*我们还必须作为自我主权实体，为他们的解放和随后的经济融合承担责任。*如果你相信这是真的，并进一步希望推动人类认识到，缺乏数据主权的数字世界是人类的一大道德失败，那么就有明确的第一步。采取这些步骤是那些希望加快推进分散解放的人义不容辞的责任:

首先，支持鼓励数据主权和用户补偿的去中心化平台和项目，并采取措施保护自己免受当代互联网的数据剥削倾向的影响。从 GMail 切换到 [ProtonMail](https://protonmail.com/) 。使用 [DuckDuckGo](https://duckduckgo.com/) 而不是谷歌来满足你的搜索需求。在 [Blockstack](https://blockstack.org/) 上建立账户。尝试用 [SocialX](https://socialx.network/roadmap/) 代替脸书， [Steemit](https://steemit.com) 代替 Reddit，以及任何一个不断增长的去中心化服务的替代品。这些新公司正处于早期阶段，因此都必须对抗其集中竞争的既定网络效应的主流逆风。但是因为维持现有网络效应的主要因素是他们的活跃用户数量，我们都保留了用我们的时间和注意力就此事投票的权力。

第二，让自己熟悉加密货币和去中心化应用的新兴世界。了解区块链的基础知识以及它们的重要性。根据我们这个技术互联的世界，重新审视你对经济学理解的首要原则。研究[金钱本身的概念](http://nakamotoinstitute.org/shelling-out/)，以及它与社会道德结构的根本联系。我们正在见证人类价值表现新时代的到来，而那些了解其轮廓的人拥有塑造未来的力量。

最后，传播你的知识。在人类道德进化的框架内阐明数据主权的理由。如果我们不能从道德上唤醒我们自己和我们的同伴，让他们意识到数据奴役的危害，那么就不会有任何有意义的力量去推动去中心化的解放或数据主权。

最重要的是，行动时要始终把人类的持续自由和完整看做有赖于此，因为它们总是如此。

[![](img/308a8d84fb9b2fab43d66c117fcc4bb4.png)](https://medium.com/swlh)

## 这篇文章发表在 [The Startup](https://medium.com/swlh) 上，这是 Medium 最大的创业刊物，拥有 337，320 多名读者。

## 在这里订阅接收[我们的头条新闻](http://growthsupply.com/the-startup-newsletter/)。

[![](img/b0164736ea17a63403e660de5dedf91a.png)](https://medium.com/swlh)