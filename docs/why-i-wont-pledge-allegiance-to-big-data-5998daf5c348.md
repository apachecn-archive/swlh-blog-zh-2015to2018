# 为什么我不会宣誓效忠大数据

> 原文：<https://medium.com/swlh/why-i-wont-pledge-allegiance-to-big-data-5998daf5c348>

![](img/f0b6efa19607bba22ea1483cef8decd6.png)

从[网上约会](http://www.bbc.com/news/business-26613909)到[你的脸书 feed 上的微定向政治广告](http://www.pbs.org/wgbh/nova/next/tech/facebook-vs-democracy/)，一个由信息和算法统治的世界已经成为新常态。然而，数据驱动的决策的兴起伴随着一个危险的客观性诡计——**数字必须是中性的错误假设。**

作为免责声明，计算机和数据科学为世界上最紧迫的社会问题提供了许多有用的，甚至是开创性的见解。它们允许研究人员在一个巨大的范围内检查历史趋势，并做出相应的高度准确的预测。此外，从[贫困和技术实验室](https://inequality.stanford.edu/stanford-technology-poverty-lab)到[空间和文本分析中心](https://cesta.stanford.edu/) (CESTA)，像斯坦福这样的研究型大学一直处于利用技术更好地了解我们周围世界的前沿。

## 然而，危险在于忘记了在代码行和大规模数据集背后是人类。

聪明的人，当然，但是容易懒惰，偏见和愚蠢的错误，就像我们其他人一样。当配备了技术的变革力量时，这些缺陷——以及它们对社会的影响——就被放大了。**算法中的错误不容易被跟踪和遏制，而是被迅速系统化和重现。**

我们已经开始看到过于信任数据的后果，以及它继续带来的危险。[“预测性警务”模型](http://www.nydailynews.com/new-york/king-predictive-policing-technological-racism-article-1.2425028)根据过去的逮捕记录告诉警察将资源集中在哪里，将反黑人偏见制度化，并减缓已经陷入 20 世纪 50 年代的警察系统的进展。当微软测试模仿人类用户的 Twitter 聊天机器人“Tay”时，她在发布后几个小时内就开始发表纳粹言论。

我认为这些技术背后的开发者无意延续仇恨和种族主义。然而，对于技术创新者来说，理解这些趋势并在未来的项目中抵消它们，同时也是一种道德义务。

## 那么，是什么让数据具有如此独特的风险，尤其是在高层决策方面？

首先，数据往往不能准确地代表一个群体。从基本统计数据中我们都知道，调查抽样会受到许多问题的影响:无回答、覆盖不足、自愿回答偏差。此外，选择偏见往往不成比例地影响已经被边缘化的社区，也许是因为他们没有互联网接入、固定电话或没有时间回答问卷。一旦你考虑到谁的经历倾向于制度化，谁的经历被系统地排除在主流叙事之外，即使是非常大的数据集也不会像看起来那样包罗万象。

**此外，数据基本上是描述性的。它确实告诉了我们过去发生了什么，但并没有为未来指明具体的行动方向。因此，我们得出的规范性结论不仅主观，而且具体化了过去的误判。例如，[圣乔治医院医学院自动化部分录取程序](https://www.theguardian.com/news/datablog/2013/aug/14/problem-with-algorithms-magnifying-misbehaviour)保留了排斥女性和非白人的历史模式。机器学习只会让这变得更加复杂，让计算机在最少的监督下拥有解释和判断的能力——当谷歌的“智能”图像识别技术[给黑人大猩猩的照片加标签时，这种风险变得很明显。](https://www.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/)’**

## 幸运的是，经常被用来压迫的分析工具可以被重新用于解放的目的，但在这个过程的每一步都必须小心谨慎。

《斯坦福社会创新评论》认为，科技公司必须在企业文化、招聘实践和评估标准中优先考虑道德问题。其他人已经为社会部门组织定义了[数据使用最佳实践](http://nonprofitwithballs.com/2015/05/weaponized-data-how-the-obsession-with-data-has-been-hurting-marginalized-communities/)；例如，直接从服务水平低下的社区购买信息，并对数据进行分类，以避免不同人群的单一化。最后，斯坦福大学和其他大学可以通过采取行动，如扩大计算机科学专业的[社会技术要求](https://ughb.stanford.edu/courses-and-planning/approved-courses/technology-society-courses-2017-18)，来扩大自己在培养以人为中心的工程中的作用。

在一个假新闻和大规模政治极化的时代，人们比以往任何时候都更倾向于接受似乎牢牢植根于经验主义和客观现实的决策策略。然而，数据不是中立的，我们不能一直保持中立。让旧的做事方式变得更快更有效率并不意味着我们进步了。

**相反，值得放慢创新的引擎，问问我们自己:*我们的算法真正在创造什么样的未来？***

—

*原载于《斯坦福日报》我的专栏*[](https://www.stanforddaily.com/author/jasminesun/)**。如果你喜欢这篇文章，可以看看我在 Medium 上写的更多内容:**

*[](/@jasmine_sun/stop-worshiping-the-myth-of-the-productive-immigrant-9cf1df78e2a4) [## 停止崇拜“高效移民”的神话

### 人类:不仅仅是“增值”

medium.com](/@jasmine_sun/stop-worshiping-the-myth-of-the-productive-immigrant-9cf1df78e2a4) [](/everyvote/politics-kills-my-friendships-and-maybe-it-should-a2b335aee98e) [## 政治扼杀了我的友谊——也许这是应该的。

### 避免基于政治意识形态的判断说起来容易做起来难——尤其是对于那些不处于…

medium.com](/everyvote/politics-kills-my-friendships-and-maybe-it-should-a2b335aee98e) ![](img/731acf26f5d44fdc58d99a6388fe935d.png)

## 这个故事发表在 [The Startup](https://medium.com/swlh) 上，这是 Medium 最大的企业家出版物，拥有 285，454+人。

## 在这里订阅接收[我们的头条新闻](http://growthsupply.com/the-startup-newsletter/)。

![](img/731acf26f5d44fdc58d99a6388fe935d.png)*